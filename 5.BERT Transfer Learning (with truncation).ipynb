{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Dropout, Input, Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFBertModel,\n",
    "    TFAutoModelForSequenceClassification,  ## https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#tfautomodelforsequenceclassification\n",
    "    TFBertForSequenceClassification,  ## https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForSequenceClassification\n",
    "    AdamW,\n",
    ")\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference from Hugging Face  \n",
    "https://huggingface.co/course/chapter3/3?fw=tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/covid19_articles_20201231_reduced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28241</td>\n",
       "      <td>The coronavirus crisis has almost certainly en...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210240</td>\n",
       "      <td>Latest Report Shows a 15.3% Week-Over-Week Dec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77957</td>\n",
       "      <td>FORESIGHT VCT PLC (Company) Publication of Sup...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207961</td>\n",
       "      <td>Technavio has been monitoring the global mater...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252956</td>\n",
       "      <td>Outdoor pop-up classes will be held in parks a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content topic_area\n",
       "0       28241  The coronavirus crisis has almost certainly en...   business\n",
       "1      210240  Latest Report Shows a 15.3% Week-Over-Week Dec...   business\n",
       "2       77957  FORESIGHT VCT PLC (Company) Publication of Sup...   business\n",
       "3      207961  Technavio has been monitoring the global mater...   business\n",
       "4      252956  Outdoor pop-up classes will be held in parks a...   business"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def clean_text(text, stemm=False, lemm=True):\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text.lower().strip())\n",
    "    text = [x for x in text.split() if x not in STOP_WORDS]\n",
    "\n",
    "    if stemm:\n",
    "        stemmer = PorterStemmer()\n",
    "        text = [stemmer.stem(x) for x in text]\n",
    "\n",
    "    if lemm:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        text = [lemmatizer.lemmatize(x) for x in text]\n",
    "\n",
    "    return \" \".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/44114463/stratified-sampling-in-pandas\n",
    "def stratified_sample_df(df, col, n_samples, random_state=69):\n",
    "    n = min(n_samples, df[col].value_counts().min())\n",
    "    df_ = df.groupby(col).apply(lambda x: x.sample(n, random_state=random_state))\n",
    "    df_.index = df_.index.droplevel(0)\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 700 entries, 5256 to 18168\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  700 non-null    int64 \n",
      " 1   content     700 non-null    object\n",
      " 2   topic_area  700 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 21.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = stratified_sample_df(df, \"topic_area\", 100)\n",
    "df[\"content\"] = df[\"content\"].apply(lambda x: clean_text(x))\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5256    craft beer live music lodging featured renovat...\n",
       "7272    flight canceled around world bar restaurant sh...\n",
       "1323    million american filed initial unemployment cl...\n",
       "4924    q mediobanca banca di credito finanziario spa ...\n",
       "5845    agence francepressegetty image covid may disru...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 20:27:52.166320: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME, truncate=True)\n",
    "sequences = df[\"content\"].tolist()\n",
    "batch = dict(tokenizer(sequences, padding=True, truncation=True, return_tensors=\"tf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "TENSOR_LENGTH = 0\n",
    "for i, r in enumerate(batch[\"input_ids\"]):\n",
    "    TENSOR_LENGTH = max(len(r), TENSOR_LENGTH)\n",
    "print(TENSOR_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample sentence:    craft beer live music lodging featured renovation plan takuya shimbo aging tokyo bathhouse hoping re...\n",
      "input ids:          [  101  7477  5404  2444  2189 26859  2956 10525  2933 27006 26230  2050\n",
      " 11895 13344 12520  5522  7198  4580  5327  5343 14059  3068 14446 27788\n",
      " 26703  4145 15029 17573  3117 21887 23350  4930  2231  8357  2900  3588\n",
      "  7198  4580  4187  2270 19548  7303  2994  2330  2051 11434  2111  2994\n",
      "  2188  2110  5057  4652  3659  2522 17258  2730  2105  2887  3465  2066\n",
      "  3095 10808  2123  2102  2689  2521  8491  8013  2056 11895 13344  2095\n",
      " 11614  2353  6914 16754  3954 18765  3683  5283 10513  8763  5522 25912\n",
      "  8013  2247 10961  9535  3436 17738 26477  2178 11703  2890 23270  7198\n",
      "  4580 10971  2404  3653]...\n",
      "token type ids:     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]...\n",
      "attention mask:     [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "Sample sentence:    {df[\"content\"].tolist()[0][:100]}...\n",
    "input ids:          {batch[\"input_ids\"][0][:100]}...\n",
    "token type ids:     {batch[\"token_type_ids\"][0][:100]}...\n",
    "attention mask:     {batch[\"attention_mask\"][0][:100]}...\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_area_map = {k: i for k, i in enumerate(df[\"topic_area\"].unique())}\n",
    "reversed_topic_area_map = {v: k for k, v in topic_area_map.items()}\n",
    "labels = tf.convert_to_tensor(\n",
    "    [reversed_topic_area_map[k] for k in df[\"topic_area\"].tolist()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL_NAME, num_labels=len(df.topic_area.unique())\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - 1241s 18s/step - loss: 3.6426 - accuracy: 0.1571\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 1289s 18s/step - loss: 1.9883 - accuracy: 0.1614\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 1364s 19s/step - loss: 1.9685 - accuracy: 0.1857\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 1402s 20s/step - loss: 1.9774 - accuracy: 0.1429\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 1356s 19s/step - loss: 1.9431 - accuracy: 0.1286\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 1570s 22s/step - loss: 1.9459 - accuracy: 0.1729\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 1094s 16s/step - loss: 1.9594 - accuracy: 0.1771\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 1196s 17s/step - loss: 2.0182 - accuracy: 0.1743\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 1155s 16s/step - loss: 1.9633 - accuracy: 0.1429\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 1054s 15s/step - loss: 1.9598 - accuracy: 0.1371\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=batch, y=labels, batch_size=10, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 00:00:08.710601: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/bert/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/bert/assets\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_FILEPATH = \"saved_models/bert\"\n",
    "model.save(BERT_MODEL_FILEPATH)\n",
    "model = tf.keras.models.load_model(BERT_MODEL_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"tf_bert_for_sequence_classification\" (type TFBertForSequenceClassification).\n    \n    Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (11 total):\n        * {'input_ids': <tf.Tensor 'input_ids_1:0' shape=(None, 7) dtype=int32>, 'token_type_ids': <tf.Tensor 'input_ids_2:0' shape=(None, 7) dtype=int32>, 'attention_mask': <tf.Tensor 'input_ids:0' shape=(None, 7) dtype=int32>}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 2 option(s):\n    \n    Option 1:\n      Positional arguments (11 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (11 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n    \n    Call arguments received:\n      • args=({'input_ids': 'tf.Tensor(shape=(None, 7), dtype=int32)', 'token_type_ids': 'tf.Tensor(shape=(None, 7), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 7), dtype=int32)'},)\n      • kwargs={'training': 'False'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sherman/Github/IS424 T4/5.BERT Transfer Learning (with truncation).ipynb Cell 16'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sherman/Github/IS424%20T4/5.BERT%20Transfer%20Learning%20%28with%20truncation%29.ipynb#ch0000013?line=0'>1</a>\u001b[0m test \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mthis is a super test\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mthis is a boring article\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sherman/Github/IS424%20T4/5.BERT%20Transfer%20Learning%20%28with%20truncation%29.ipynb#ch0000013?line=1'>2</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(tokenizer(test, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sherman/Github/IS424%20T4/5.BERT%20Transfer%20Learning%20%28with%20truncation%29.ipynb#ch0000013?line=2'>3</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(batch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.9/site-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"tf_bert_for_sequence_classification\" (type TFBertForSequenceClassification).\n    \n    Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (11 total):\n        * {'input_ids': <tf.Tensor 'input_ids_1:0' shape=(None, 7) dtype=int32>, 'token_type_ids': <tf.Tensor 'input_ids_2:0' shape=(None, 7) dtype=int32>, 'attention_mask': <tf.Tensor 'input_ids:0' shape=(None, 7) dtype=int32>}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 2 option(s):\n    \n    Option 1:\n      Positional arguments (11 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * False\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (11 total):\n        * {'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids/input_ids')}\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * None\n        * True\n      Keyword arguments: {}\n    \n    Call arguments received:\n      • args=({'input_ids': 'tf.Tensor(shape=(None, 7), dtype=int32)', 'token_type_ids': 'tf.Tensor(shape=(None, 7), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 7), dtype=int32)'},)\n      • kwargs={'training': 'False'}\n"
     ]
    }
   ],
   "source": [
    "test = [\"this is a super test\", \"this is a boring article\"]\n",
    "batch = dict(tokenizer(test, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "y_pred = model.predict(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.8829320669174194,\n",
       "  1.4541959762573242,\n",
       "  1.1529698371887207,\n",
       "  3.1338181495666504,\n",
       "  2.0458924770355225,\n",
       "  -0.9047433733940125,\n",
       "  -1.2239004373550415],\n",
       " [-0.8821392059326172,\n",
       "  1.4532511234283447,\n",
       "  1.1529271602630615,\n",
       "  3.132197380065918,\n",
       "  2.0450141429901123,\n",
       "  -0.9033188819885254,\n",
       "  -1.2226083278656006]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.to_tuple()[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
