{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with BERT\n",
    "\n",
    "References:\n",
    "\n",
    "- https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "- https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    TFBertModel,\n",
    "    AutoTokenizer,\n",
    "    BertTokenizerFast,\n",
    "    AutoModel,\n",
    "    DistilBertTokenizerFast,\n",
    ")\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Dense\n",
    "import regex as re\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/covid19_articles_20201231_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28241</td>\n",
       "      <td>The coronavirus crisis has almost certainly en...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210240</td>\n",
       "      <td>Latest Report Shows a 15.3% Week-Over-Week Dec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77957</td>\n",
       "      <td>FORESIGHT VCT PLC (Company) Publication of Sup...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207961</td>\n",
       "      <td>Technavio has been monitoring the global mater...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252956</td>\n",
       "      <td>Outdoor pop-up classes will be held in parks a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content topic_area\n",
       "0       28241  The coronavirus crisis has almost certainly en...   business\n",
       "1      210240  Latest Report Shows a 15.3% Week-Over-Week Dec...   business\n",
       "2       77957  FORESIGHT VCT PLC (Company) Publication of Sup...   business\n",
       "3      207961  Technavio has been monitoring the global mater...   business\n",
       "4      252956  Outdoor pop-up classes will be held in parks a...   business"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE ME\n",
    "_, X_train, __, y_train = train_test_split(\n",
    "    df[\"content\"],\n",
    "    df[\"topic_area\"],\n",
    "    test_size=0.005,\n",
    "    stratify=df[\"topic_area\"],\n",
    "    random_state=69,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lightweight version of bert\n",
    "## https://huggingface.co/docs/transformers/preprocessing\n",
    "BERT_MODEL_NAME = \"bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BERT_MODEL_NAME, do_lower_case=True, padding=True, truncation=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100\n",
    "\n",
    "\n",
    "def bert_encode(corpus, max_length):\n",
    "    res = [[], [], []]\n",
    "    for sentence in corpus:\n",
    "        sentence = (\n",
    "            [\"[CLS]\"]\n",
    "            + [\n",
    "                \" \".join(tokenizer.tokenize(x))\n",
    "                for x in (re.sub(r\"[^\\w\\s]+|\\n\", \"\", sentence))\n",
    "                .lower()\n",
    "                .strip()\n",
    "                .split(\" \")\n",
    "                if x.strip() != \"\"\n",
    "            ][: max_length // 4]\n",
    "            + [\"[SEP]\"]\n",
    "        )\n",
    "\n",
    "        tokens = [\n",
    "            inner\n",
    "            for outer in [tokenizer.encode(x)[1:-1] for x in sentence]\n",
    "            for inner in outer\n",
    "        ]\n",
    "\n",
    "        ## padding\n",
    "        tokens = tokens + [0] * max(0, max_length - len(tokens))\n",
    "\n",
    "        mask = []\n",
    "        segment = []\n",
    "        m, s = 1, 0\n",
    "        for t in tokens:\n",
    "            if t == 102:\n",
    "                m, s = 0, 1\n",
    "            mask.append(m)\n",
    "            segment.append(s)\n",
    "        res[0].append(tokens)\n",
    "        res[1].append(mask)\n",
    "        res[2].append(segment)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = bert_encode(X_train, MAX_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLengths = [0, 0, 0]\n",
    "for i in range(len(X_train_encoded)):\n",
    "    for j in range(3):\n",
    "        maxLengths[j] = max(maxLengths[j], len(X_train_encoded[j][i]))\n",
    "maxLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
