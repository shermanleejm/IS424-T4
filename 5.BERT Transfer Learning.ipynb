{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, Dropout, Input, Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFBertModel,\n",
    "    TFAutoModelForSequenceClassification,  ## https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#tfautomodelforsequenceclassification\n",
    "    TFBertForSequenceClassification,  ## https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForSequenceClassification\n",
    "    AdamW,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference from Hugging Face  \n",
    "https://huggingface.co/course/chapter3/3?fw=tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/covid19_articles_20201231_reduced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>content</th>\n",
       "      <th>topic_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28241</td>\n",
       "      <td>The coronavirus crisis has almost certainly en...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210240</td>\n",
       "      <td>Latest Report Shows a 15.3% Week-Over-Week Dec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77957</td>\n",
       "      <td>FORESIGHT VCT PLC (Company) Publication of Sup...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207961</td>\n",
       "      <td>Technavio has been monitoring the global mater...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252956</td>\n",
       "      <td>Outdoor pop-up classes will be held in parks a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            content topic_area\n",
       "0       28241  The coronavirus crisis has almost certainly en...   business\n",
       "1      210240  Latest Report Shows a 15.3% Week-Over-Week Dec...   business\n",
       "2       77957  FORESIGHT VCT PLC (Company) Publication of Sup...   business\n",
       "3      207961  Technavio has been monitoring the global mater...   business\n",
       "4      252956  Outdoor pop-up classes will be held in parks a...   business"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/44114463/stratified-sampling-in-pandas\n",
    "def stratified_sample_df(df, col, n_samples, random_state=69):\n",
    "    n = min(n_samples, df[col].value_counts().min())\n",
    "    df_ = df.groupby(col).apply(lambda x: x.sample(n, random_state=random_state))\n",
    "    df_.index = df_.index.droplevel(0)\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 700 entries, 5256 to 18168\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  700 non-null    int64 \n",
      " 1   content     700 non-null    object\n",
      " 2   topic_area  700 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 21.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = stratified_sample_df(df, \"topic_area\", 100)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BERT_MODEL_NAME, truncate=True, max_length=100\n",
    ")\n",
    "sequences = df[\"content\"].tolist()\n",
    "batch = dict(tokenizer(sequences, padding=True, truncation=True, return_tensors=\"tf\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "TENSOR_LENGTH = 0\n",
    "for i, r in enumerate(batch[\"input_ids\"]):\n",
    "    TENSOR_LENGTH = max(len(r), TENSOR_LENGTH)\n",
    "print(TENSOR_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample sentence:     - Craft beer, live music and lodging featured in renovation plans that Takuya Shimbo had for an agi...\n",
      "input ids:          [  101  1011  7477  5404  1010  2444  2189  1998 26859  2956  1999 10525\n",
      "  3488  2008 27006 26230  2050 11895 13344  2018  2005  2019 12520  5522\n",
      "  7198  4580  1010  5327  2000  5343  1037 14059  3068  2013 14446  2011\n",
      " 27788 26703  1996  4145  1997 15029 17573  1012  2059  1996  3117 21887\n",
      " 23350  4930  1012  1996  2231  8357  2900  1005  1055  2261  3588  7198\n",
      " 15666  2004  4187  2005  2270 19548  2061  2009  7303  2027  2994  2330\n",
      "  1010  2096  2012  1996  2168  2051 11434  2111  2000  2994  2012  2188\n",
      "  2076  1037  2110  1997  5057  2000  4652  1996  3659  1997  2522 17258\n",
      "  1011  2539  2029  2038]...\n",
      "token type ids:     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]...\n",
      "attention mask:     [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "Sample sentence:    {df[\"content\"].tolist()[0][:100]}...\n",
    "input ids:          {batch[\"input_ids\"][0][:100]}...\n",
    "token type ids:     {batch[\"token_type_ids\"][0][:100]}...\n",
    "attention mask:     {batch[\"attention_mask\"][0][:100]}...\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_area_map = {k: i for k, i in enumerate(df[\"topic_area\"].unique())}\n",
    "reversed_topic_area_map = {v: k for k, v in topic_area_map.items()}\n",
    "labels = tf.convert_to_tensor(\n",
    "    [reversed_topic_area_map[k] for k in df[\"topic_area\"].tolist()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL_NAME, num_labels=len(df.topic_area.unique())\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "63/63 [==============================] - 1221s 19s/step - loss: 3.0149 - accuracy: 0.1635 - val_loss: 16.9785 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1404s 22s/step - loss: 2.4600 - accuracy: 0.2127 - val_loss: 16.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1300s 21s/step - loss: 2.2916 - accuracy: 0.3429 - val_loss: 16.5019 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=batch, y=labels, batch_size=10, epochs=3, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 12:04:50.061784: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/bert/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/bert/assets\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL_FILEPATH = \"saved_models/bert\"\n",
    "model.save(BERT_MODEL_FILEPATH)\n",
    "model = tf.keras.models.load_model(BERT_MODEL_FILEPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"this is a super test\", \"this is a boring article\"]\n",
    "batch = dict(tokenizer(test, padding=True, truncation=True, return_tensors=\"tf\"))\n",
    "y_pred = model.predict(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.8829320669174194,\n",
       "  1.4541959762573242,\n",
       "  1.1529698371887207,\n",
       "  3.1338181495666504,\n",
       "  2.0458924770355225,\n",
       "  -0.9047433733940125,\n",
       "  -1.2239004373550415],\n",
       " [-0.8821392059326172,\n",
       "  1.4532511234283447,\n",
       "  1.1529271602630615,\n",
       "  3.132197380065918,\n",
       "  2.0450141429901123,\n",
       "  -0.9033188819885254,\n",
       "  -1.2226083278656006]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.to_tuple()[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
